\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\setlength{\parindent}{4em}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1.5}
\begin{document}
Raina Sabharwal NetID: rs1136
\\
Yunqi Shen NetID: ys478
\\
Question 1
\\
\\
Question 2
\\
a) The decision tree in Figure 4 correctly categorizes the provided examples.
\\
b) $Gain(A) = I(\frac{p}{p+n}, \frac{n}{p+n}) - $$\sum_{i=1}^{n} \frac{p_{i} +n_{i}}{p+n}I(\frac{p_{i}}{p_{i}+n_{i}}, \frac{n_{i}}{p_{i}+n_{i}}) $$ $
\\
$Gain(GPA) = 1 - [\frac{3}{12}I(1,0)+\frac{5}{12}I(\frac{3}{5},\frac{2}{5})+\frac{4}{12}I(0,1)] \approx 0.595$
\\
$Gain(University) = 1 -  [\frac{5}{12}I(\frac{3}{5},\frac{2}{5})+\frac{3}{12}I(\frac{2}{3},\frac{1}{3})+\frac{4}{12}I(\frac{1}{4},\frac{3}{4})] \approx 0.095$
\\
$Gain(Published) = 1 -  [\frac{5}{12}I(\frac{3}{5},\frac{2}{5})+\frac{7}{12}I(\frac{3}{7},\frac{4}{7})] \approx 0.021$
\\
$Gain(Recommendation) = 1 -  [\frac{8}{12}I(\frac{5}{8},\frac{3}{8})+\frac{4}{12}I(\frac{1}{4},\frac{3}{4})] \approx 0.093$
\\
1st level: GPA because the information gain is highest
\\
$Gain(University) = I(\frac{3}{5}, \frac{2}{5}) -  [\frac{2}{5}I(\frac{1}{2},\frac{1}{2})+\frac{1}{5}I(1,0)+\frac{2}{5}I(\frac{1}{2},\frac{1}{2})] \approx 0.171$
\\
$Gain(Published) = I(\frac{3}{5}, \frac{2}{5})  -  [\frac{2}{5}I(1,0)+\frac{3}{5}I(\frac{1}{3},\frac{2}{3})] \approx 0.420$
\\
$Gain(Recommendation) = I(\frac{3}{5}, \frac{2}{5})  -  [I(\frac{3}{5},\frac{2}{5})] = 0 $
\\
2nd level: Published because the information gain is highest
\\
$Gain(University) = I(\frac{1}{3}, \frac{2}{3}) -  [\frac{1}{3}I(0,1)+\frac{1}{3}I(1,0)+\frac{1}{3}I(0,1)] \approx 0.918$
\\
$Gain(Recommendation) = I(\frac{1}{3}, \frac{2}{3})  -  [I(\frac{1}{3},\frac{2}{3})] = 0 $
\\
3rd level: University because the information gain is highest
\\
The tree is :
\includegraphics{dtree.png}
\\
c) The trees are equivalent. This is a coincidence because we were provided with the best decision tree. This data set, to me, did not have an obvious decision tree simply by looking at the table so information gains must be calculated.
\\
\\
Question 3
\\
a) \includegraphics{svm1.png}
\\
b) The decision boundary lies on $y = -x+4$. We have a positive support vector at (0,2) with line equation $y=-x+2$ and a negative support vector at (1,5) with line equation $y = -x+6$
\\
So $w = (-\frac{1}{2}, -\frac{1}{2})$ and $b = 2 $
\\
c) The linear SVM is the same as in part b. $w = (-\frac{1}{2}, -\frac{1}{2})$ and $b = 2 $
\\
\\
Question 4
\\
a) $w_{0}(0) = 0.2, w_{1}(0)= 1, w_{2}(0) = -1$
\\ $w_{1}i_{1}+w_{2}i_{2} + w_{0} = 0$
\\ $i_{1}-i{2}+0.2=0$
\\ Giving us the following initial decision boundary:
\\
 \includegraphics{perceptron.png}
\\ 4 samples are misclassified
\\ $i(n) = i(0) = [1, 0.93, 0.45]^{T}$ and $ d(0) = -1$
\\ $w(n) = w(0)= [0.2, 1, -1]^{T}$
\\ $y(n) = y(0) = sgn(w^{T}(0)i(0)) = sgn(0.2+0.93-0.45) = sgn(0.68) = +1 \neq d(0)$
\\ $w(n+1) = w(n) + \eta [d(n) - y(n)]i(n)$
\\ $ y(1) = 1$
\\ $ w(1) = [0.2, 1, -1]^{T} +[-1-1][1, 0.93, 0.45]^{T}= [0.2, 1, -1]^{T} +[-2, -1.86, -0.9]^{T}= [-1.8,-0.86,-1.9]^{T}$
\\  \includegraphics{perceptron1.png}
\\ $i(n) = i(1) = [1, 0.08, 0.73]^{T}$ and $ d(0) = 1$
\\ $w(n) = w(1)=[-1.8,-0.86,-1.9]^{T}$
\\ $y(n) = y(1) = sgn(-1.8-0.0688-1.378) = -1 \neq d(0)$
\\ $ w(2) = [-1.8,-0.86,-1.9]^{T} +[1+1][1, 0.08, 0.73]^{T}= [-1.8,-0.86,-1.9]^{T} +[2, 0.16, 1.46]^{T}= [0.2,-0.7,-0.44]^{T}$
\\  \includegraphics{perceptron2.png}
\\ $i(n) = i(2) = [1, 0.28, 0.58]^{T}$ and $ d(0) = 1$
\\ $w(n) = w(2)=[0.2,-0.7,-0.44]^{T}$
\\ $y(n) = y(2) = sgn(0.2-0.196-0.2552) = -1 \neq d(0)$
\\ $ w(3) = [0.2,-0.7,-0.44]^{T} +[1+1][1, 0.28, 0.58]^{T}= [0.2,-0.7,-0.44]^{T} +[2, 0.56, 1.16]^{T}= [2.2,-0.14,0.72]^{T}$
\\  \includegraphics{perceptron3.png}
\\ $i(n) = i(3) = [1, 0.1, 1]^{T}$ and $ d(0) = -1$
\\ $w(n) = w(3)=[2.2,-0.14,0.72]^{T}$
\\ $y(n) = y(3) = sgn(2.2-0.014+0.72) = 1 \neq d(0)$
\\ $ w(4) = [2.2,-0.14,0.72]^{T} +[-1-1][1, 0.1, 1]^{T}= [2.2,-0.14,0.72]^{T} +[-2, -0.2, -2]^{T}= [-4.4,-0.028,-1.28]^{T}$
\\  \includegraphics{perceptron4.png}
\\ $i(n) = i(4) = [1, 0.6, 0.3]^{T}$ and $ d(0) = 1$
\\ $w(n) = w(4)=[-4.4,-0.028,-1.28]^{T}$
\\ $y(n) = y(4) = sgn(-4.4-0.0168-0.384) = -1 \neq d(0)$
\\ $ w(5) = [-4.4,-0.028,-1.28]^{T} +[1+1][1, 0.6, 0.3]^{T}= [-4.4,-0.028,-1.28]^{T} +[2, 1.2, 0.6]^{T}= [-2.4,1.172,-0.68]^{T}$
\\  \includegraphics{perceptron5.png}
\\
b) $w = (-0.875, -1)$ and $b = 0.95625$
\\ \includegraphics{perceptron6.png}
\\
c) 
\end{document}